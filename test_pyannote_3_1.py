#!/usr/bin/env python3
"""
ä¸“é—¨æµ‹è¯• pyannote/speaker-diarization-3.1 çš„è„šæœ¬
"""

import os
import sys
import torch

def test_3_1_loading():
    """æµ‹è¯•3.1ç‰ˆæœ¬åŠ è½½çš„è¯¦ç»†è¿‡ç¨‹"""

    print("ğŸ”§ æµ‹è¯• pyannote/speaker-diarization-3.1 åŠ è½½è¿‡ç¨‹")
    print("=" * 60)

    # è®¾ç½®è®¤è¯
    print("ğŸ” è®¾ç½®è®¤è¯...")
    token = os.getenv('HF_TOKEN') or True
    print(f"Token ç±»å‹: {type(token)}")

    # æ£€æŸ¥ GPU
    print(f"ğŸ® CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU æ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")

    try:
        print("\nğŸ“¡ æ­¥éª¤ 1: å¯¼å…¥ Pipeline...")
        from pyannote.audio import Pipeline
        print("âœ… Pipeline å¯¼å…¥æˆåŠŸ")

        print("\nğŸ“¡ æ­¥éª¤ 2: åŠ è½½ 3.1 ç‰ˆæœ¬...")
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=token
        )
        print("âœ… Pipeline å¯¹è±¡åˆ›å»ºæˆåŠŸ")
        print(f"Pipeline ç±»å‹: {type(pipeline)}")
        print(f"Pipeline: {pipeline}")

        print("\nğŸ“¡ æ­¥éª¤ 3: è®¾ç½® GPU è®¾å¤‡...")
        if torch.cuda.is_available():
            device = torch.device("cuda")
            pipeline.to(device)
            print("âœ… Pipeline å·²ç§»åˆ° GPU")
        else:
            print("â„¹ï¸ ä½¿ç”¨ CPU æ¨¡å¼")

        print("\nğŸ‰ 3.1 ç‰ˆæœ¬åŠ è½½å®Œå…¨æˆåŠŸ!")
        return pipeline

    except Exception as e:
        print(f"\nâŒ åŠ è½½å¤±è´¥: {type(e).__name__}: {e}")

        # è¯¦ç»†è°ƒè¯•ä¿¡æ¯
        import traceback
        print("\nğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()

        return None

def test_dependencies():
    """æµ‹è¯•3.1ç‰ˆæœ¬çš„ä¾èµ–æ¨¡å‹"""

    print("\nğŸ” æµ‹è¯•ä¾èµ–æ¨¡å‹...")

    dependencies = [
        "pyannote/segmentation-3.0",
        "pyannote/wespeaker-voxceleb-resnet34-LM"
    ]

    token = os.getenv('HF_TOKEN') or True

    for dep in dependencies:
        try:
            print(f"ğŸ“¡ æµ‹è¯• {dep}...")
            from pyannote.audio import Model
            model = Model.from_pretrained(dep, use_auth_token=token)
            print(f"âœ… {dep} å¯ç”¨")
        except Exception as e:
            print(f"âŒ {dep} å¤±è´¥: {e}")

def test_with_audio():
    """ä½¿ç”¨çœŸå®éŸ³é¢‘æµ‹è¯•"""

    print("\nğŸµ ä½¿ç”¨éŸ³é¢‘æ–‡ä»¶æµ‹è¯•...")

    audio_file = "server/temp/audio_1756810032503_50wk4cx6x.m4a"

    if not os.path.exists(audio_file):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return

    pipeline = test_3_1_loading()
    if pipeline is None:
        print("âŒ Pipeline åŠ è½½å¤±è´¥ï¼Œè·³è¿‡éŸ³é¢‘æµ‹è¯•")
        return

    try:
        print(f"ğŸ¤ å¤„ç†éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_file)}")

        # æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
        diarization = pipeline(audio_file)

        print("âœ… è¯´è¯äººåˆ†ç¦»æˆåŠŸ!")

        # ç»Ÿè®¡ç»“æœ
        speakers = set()
        segments = 0

        for turn, _, speaker in diarization.itertracks(yield_label=True):
            speakers.add(speaker)
            segments += 1

        print(f"ğŸ“Š ç»“æœç»Ÿè®¡:")
        print(f"   - æ£€æµ‹åˆ° {len(speakers)} ä¸ªè¯´è¯äºº")
        print(f"   - åˆ†å‰²ä¸º {segments} ä¸ªç‰‡æ®µ")
        print(f"   - è¯´è¯äººåˆ—è¡¨: {sorted(speakers)}")

        return True

    except Exception as e:
        print(f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("ğŸ­ PyAnnote 3.1 ä¸“é¡¹æµ‹è¯•")

    # æµ‹è¯•ä¾èµ–
    test_dependencies()

    # æµ‹è¯•åŠ è½½
    pipeline = test_3_1_loading()

    if pipeline:
        # æµ‹è¯•éŸ³é¢‘å¤„ç†
        success = test_with_audio()

        if success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! 3.1 ç‰ˆæœ¬å®Œå…¨å¯ç”¨")
            return True

    print("\nâŒ æµ‹è¯•å¤±è´¥")
    return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)