播客分析全流程需求说明文档
一、项目目标

开发一个自动化 播客分析系统，能够处理长音频（30 分钟 – 2 小时），完成以下任务：

自动识别人声并区分不同说话人（主持人、嘉宾等）。

自动进行语音转写（ASR），生成完整文字稿。

将说话人标签与文字内容对齐，输出“谁在说什么”。

在此基础上进行内容分析（摘要、关键词提取等）。

最终产出形式可以是结构化数据（JSON）、Markdown 文档或网页展示。

二、功能需求
1. 音频输入

输入音频格式：mp3 / wav / flac

音频时长：30 分钟 – 2 小时

多说话人，无重叠语音（假设场景为播客，发言人交替讲话）

2. 语音处理流程
(1) 语音活动检测（VAD）

检测并去除静音段、音乐片头、广告等非语音内容。

输出切分后的有效语音片段。

(2) 说话人分割 / 区分（Diarization）

工具：pyannote.audio

输出：时间段 + 说话人标签，例如：

[00:00 – 00:45] Speaker 1
[00:46 – 01:32] Speaker 2

(3) 语音转写（ASR）

工具可选：

Whisper (large-v2) —— 英文播客优先

SenseVoice —— 中英文混合播客优先

输出：带时间戳的文本片段。

(4) 对齐

将 说话人分割结果 与 转写文本 对齐。

输出格式：

Speaker 1 [00:00 – 00:45]: 欢迎大家收听今天的播客...
Speaker 2 [00:46 – 01:32]: 很高兴来到这里分享...

3. 内容分析（可选）

摘要生成：总结整集播客内容、每个话题要点。

关键词提取：提取播客中的核心主题词。

情绪/语气识别（可用 SenseVoice 自带的情绪分类器）。

三、非功能需求

性能：支持处理 1 小时音频，单 GPU/CPU 下可在 1.5x 实时率内完成。

可扩展性：支持新增情绪识别、话题分类等功能。

可维护性：各模块（VAD、Diarization、ASR、分析）独立，可替换。

四、输出形式

Markdown 文档

## 播客纪要
- **Speaker 1** (主持人): 欢迎大家收听今天的播客...
- **Speaker 2** (嘉宾): 很高兴来到这里分享...


JSON 格式

[
  {
    "speaker": "Speaker 1",
    "start": "00:00",
    "end": "00:45",
    "text": "欢迎大家收听今天的播客..."
  },
  {
    "speaker": "Speaker 2",
    "start": "00:46",
    "end": "01:32",
    "text": "很高兴来到这里分享..."
  }
]


可视化播放器（可选）

带逐句字幕 + 发言人标签的网页播放器。

五、技术栈建议

语音活动检测 (VAD)：pyannote.audio 或 SenseVoice 内置 VAD

说话人分割 / 区分：pyannote.audio

ASR 转写：Whisper / SenseVoice

内容分析：大语言模型（GPT / DeepSeek / Qwen）

数据存储 / 检索（可选）：FAISS / Weaviate，用于后续播客内容搜索

六、示例流程图
播客音频 → VAD 去静音
          → 说话人分割 (pyannote) ─┐
          → 语音转写 (Whisper/SenseVoice) ─┤→ 对齐 → 带说话人标签的文字稿
                                         → 内容分析 → 摘要 / 关键词


这样一份文档直接给编程 AI 工具，它就能清楚知道要搭建什么 pipeline、用哪些库、输入输出是什么。
