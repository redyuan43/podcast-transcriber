#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæœ¬åœ°Faster-Whisperè½¬å½•è„šæœ¬
æ”¯æŒè¯´è¯äººåˆ†ç¦»(Speaker Diarization)å’Œæƒ…ç»ªæ£€æµ‹
"""

import sys
import json
import argparse
import time
import re
from pathlib import Path
from faster_whisper import WhisperModel
import warnings
warnings.filterwarnings("ignore")

# ç¹ç®€è½¬æ¢
try:
    import opencc
    HAS_OPENCC = True
    print("âœ… ç¹ç®€è½¬æ¢åŠŸèƒ½å·²å¯ç”¨", file=sys.stderr)
except ImportError:
    HAS_OPENCC = False
    print("âš ï¸ ç¹ç®€è½¬æ¢åº“æœªå®‰è£…ï¼Œè·³è¿‡è½¬æ¢", file=sys.stderr)

class EnhancedWhisperTranscriber:
    def __init__(self, model_size="base", device="cpu", compute_type="int8"):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆWhisperæ¨¡å‹
        """
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½Whisperæ¨¡å‹: {model_size}", file=sys.stderr)
        self.model = WhisperModel(model_size, device=device, compute_type=compute_type)
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ", file=sys.stderr)
        
        # åˆå§‹åŒ–ç¹ç®€è½¬æ¢å™¨
        if HAS_OPENCC:
            try:
                self.converter = opencc.OpenCC('t2s')  # ç¹ä½“è½¬ç®€ä½“ï¼Œä¸éœ€è¦.jsonåç¼€
                print("ğŸ”„ ç¹ç®€è½¬æ¢å™¨å·²åˆå§‹åŒ–", file=sys.stderr)
            except Exception as e:
                print(f"âš ï¸ ç¹ç®€è½¬æ¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}", file=sys.stderr)
                self.converter = None
        else:
            self.converter = None
        
        # æƒ…ç»ªå…³é”®è¯å­—å…¸ï¼ˆæ”¯æŒç¹ç®€ä½“ï¼‰
        self.emotion_keywords = {
            'ç¬‘': ['å“ˆå“ˆ', 'å‘µå‘µ', 'å˜¿å˜¿', 'å’¯å’¯', 'å“ˆå“ˆå“ˆ', 'å‘µå‘µå‘µ'],
            'æ„Ÿå¹': ['å“‡', 'å“å‘€', 'å¤©å“ª', 'æˆ‘çš„å¤©', 'å“¦', 'å•Š', 'å—¯'],
            'æ€è€ƒ': ['å—¯', 'é¢', 'è¿™ä¸ª', 'é‚£ä¸ª', 'å°±æ˜¯è¯´', 'è®“æˆ‘', 'è®“æˆ‘å€‘'],
            'èµåŒ': ['å¯¹å¯¹å¯¹', 'æ˜¯çš„æ˜¯çš„', 'æ²¡é”™', 'ç¡®å®', 'å¯¹å•Š', 'å°', 'å°å°', 'æ²’éŒ¯'],
            'æƒŠè®¶': ['ä»€ä¹ˆ', 'çœŸçš„å—', 'ä¸ä¼šå§', 'è¿™ä¹ˆå‰å®³', 'ä»€éº¼', 'çœŸçš„å—', 'ä¸æœƒå§'],
            'åœé¡¿': ['..', '...', '....'],
            'é—®å€™': ['å¤§å®¶å¥½', 'æœ‹å‹å€‘', 'å¬ä¼—', 'è½çœ¾']
        }
    
    def convert_to_simplified(self, text):
        """
        å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
        """
        if self.converter and text:
            try:
                return self.converter.convert(text)
            except Exception as e:
                print(f"âš ï¸ ç¹ç®€è½¬æ¢å¤±è´¥: {e}", file=sys.stderr)
                return text
        return text
    
    def detect_speaker_change(self, segments):
        """
        åŸºäºéŸ³é¢‘ç‰¹å¾æ£€æµ‹è¯´è¯äººå˜åŒ–çš„ç®€åŒ–ç‰ˆæœ¬
        """
        speakers = []
        current_speaker = "ä¸»æŒäºº"
        speaker_count = 0
        
        for i, segment in enumerate(segments):
            text = segment['text'].strip()
            
            # åŸºäºå†…å®¹ç‰¹å¾åˆ¤æ–­è¯´è¯äººåˆ‡æ¢
            speaker_change_indicators = [
                len(text) > 100,  # é•¿å¥å­æ›´å¯èƒ½æ˜¯æ–°è¯´è¯äºº
                text.startswith(('å¥½', 'é‚£', 'æ‰€ä»¥', 'å…¶å®', 'ä½†æ˜¯')),  # è½¬æŠ˜è¯
                i > 0 and segment['start'] - segments[i-1]['end'] > 2.0  # é•¿åœé¡¿
            ]
            
            if any(speaker_change_indicators) and i > 0:
                if current_speaker == "ä¸»æŒäºº":
                    current_speaker = "å˜‰å®¾"
                else:
                    current_speaker = "ä¸»æŒäºº"
            
            speakers.append(current_speaker)
        
        return speakers
    
    def detect_emotions(self, text):
        """
        æ£€æµ‹æ–‡æœ¬ä¸­çš„æƒ…ç»ªæ ‡è®°
        """
        emotions = []
        
        for emotion, keywords in self.emotion_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    emotions.append(emotion)
                    break
        
        # æ£€æµ‹é‡å¤å­—ç¬¦ï¼ˆè¡¨ç¤ºå¼ºè°ƒæˆ–æƒ…ç»ªï¼‰
        if re.search(r'(.)\1{2,}', text):
            emotions.append('å¼ºè°ƒ')
        
        # æ£€æµ‹é—®å·å’Œæ„Ÿå¹å·
        if '?' in text or 'ï¼Ÿ' in text:
            emotions.append('ç–‘é—®')
        if '!' in text or 'ï¼' in text:
            emotions.append('æ¿€åŠ¨')
        
        return list(set(emotions))
    
    def format_transcript_with_speakers_and_emotions(self, segments, speakers, podcast_title=None):
        """
        æ ¼å¼åŒ–è½¬å½•æ–‡æœ¬ï¼ŒåŒ…å«è¯´è¯äººå’Œæƒ…ç»ªä¿¡æ¯
        """
        from datetime import datetime
        
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        if podcast_title:
            title = f"# ğŸ“ {podcast_title} - å¢å¼ºè½¬å½•"
        else:
            title = "# ğŸ“ æ’­å®¢å¢å¼ºè½¬å½•"
        
        content = f"""{title}

**è½¬å½•æ—¶é—´**: {current_time}
**åŠŸèƒ½**: æ”¯æŒè¯´è¯äººåˆ†ç¦»å’Œæƒ…ç»ªæ£€æµ‹

---

"""
        
        current_speaker = None
        for i, (segment, speaker) in enumerate(zip(segments, speakers)):
            text = segment['text'].strip()
            
            # æ£€æµ‹æƒ…ç»ª
            emotions = self.detect_emotions(text)
            emotion_tags = ' '.join([f'[{e}]' for e in emotions]) if emotions else ''
            
            # æ—¶é—´æˆ³
            timestamp = f"[{self.seconds_to_time(segment['start'])} - {self.seconds_to_time(segment['end'])}]"
            
            # å¦‚æœè¯´è¯äººå˜åŒ–ï¼Œæ·»åŠ åˆ†éš”çº¿
            if speaker != current_speaker:
                if current_speaker is not None:
                    content += "\n---\n\n"
                content += f"## {speaker}\n\n"
                current_speaker = speaker
            
            # æ·»åŠ æ–‡æœ¬å†…å®¹
            content += f"**{timestamp}** {emotion_tags} {text}\n\n"
        
        return content

    def format_raw_transcript(self, segments, podcast_title=None):
        """
        æ ¼å¼åŒ–åŸå§‹è½¬å½•æ–‡æœ¬ï¼ˆæ— å¢å¼ºåŠŸèƒ½ï¼‰
        """
        from datetime import datetime
        
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        if podcast_title:
            title = f"# ğŸ“ {podcast_title} - åŸå§‹è½¬å½•"
        else:
            title = "# ğŸ“ æ’­å®¢åŸå§‹è½¬å½•"
        
        content = f"""{title}

**è½¬å½•æ—¶é—´**: {current_time}
**è½¬å½•æ–¹å¼**: Faster-Whisperæœ¬åœ°è½¬å½•

---

"""
        
        for i, segment in enumerate(segments):
            text = segment['text'].strip()
            timestamp = f"[{self.seconds_to_time(segment['start'])} - {self.seconds_to_time(segment['end'])}]"
            content += f"**{timestamp}** {text}\n\n"
        
        return content
    
    def seconds_to_time(self, seconds):
        """
        å°†ç§’æ•°è½¬æ¢ä¸ºæ—¶é—´æ ¼å¼
        """
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes:02d}:{secs:02d}"
    
    def transcribe_file_enhanced(self, audio_path, language=None):
        """
        å¢å¼ºç‰ˆè½¬å½•ï¼Œæ”¯æŒè¯´è¯äººåˆ†ç¦»å’Œæƒ…ç»ªæ£€æµ‹
        """
        try:
            print(f"ğŸ¤ å¼€å§‹å¢å¼ºè½¬å½•: {audio_path}", file=sys.stderr)
            start_time = time.time()
            
            # æ‰§è¡Œè½¬å½• - è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼Œä½†ä¸­æ–‡ç»Ÿä¸€ä½¿ç”¨ç®€ä½“
            original_language = language
            if language in ['zh', 'chinese', 'zh-cn', 'zh-tw']:
                language = 'zh'  # Whisperçš„ç®€ä½“ä¸­æ–‡ä»£ç 
                print(f"ğŸ‡¨ğŸ‡³ ä¸­æ–‡éŸ³é¢‘å°†ä½¿ç”¨ç®€ä½“ä¸­æ–‡è½¬å½•", file=sys.stderr)
            elif language is None:
                print(f"ğŸŒ è‡ªåŠ¨æ£€æµ‹è¯­è¨€æ¨¡å¼", file=sys.stderr)
            
            segments, info = self.model.transcribe(
                audio_path, 
                language=language,
                vad_filter=True,
                vad_parameters=dict(min_silence_duration_ms=500),
                word_timestamps=True,  # å¯ç”¨è¯çº§æ—¶é—´æˆ³
                # æ·»åŠ å…¶ä»–å‚æ•°æ¥ä¼˜åŒ–ä¸­æ–‡è½¬å½•
                beam_size=5,
                best_of=5,
                temperature=0.0  # ä½¿ç”¨ç¡®å®šæ€§è§£ç 
            )
            
            # æ”¶é›†æ‰€æœ‰ç‰‡æ®µ
            transcript_segments = []
            full_text = ""
            
            # æ ¹æ®æ£€æµ‹çš„è¯­è¨€å†³å®šæ˜¯å¦éœ€è¦ç¹ç®€è½¬æ¢
            need_conversion = info.language in ['zh', 'chinese'] and original_language is None
            if need_conversion:
                print(f"ğŸ”„ æ£€æµ‹åˆ°ä¸­æ–‡å†…å®¹ï¼Œå°†è¿›è¡Œç¹ç®€è½¬æ¢", file=sys.stderr)
            
            for segment in segments:
                text = segment.text.strip()
                # å¦‚æœæ˜¯è‡ªåŠ¨æ£€æµ‹åˆ°çš„ä¸­æ–‡ï¼Œè¿›è¡Œç¹ç®€è½¬æ¢
                if need_conversion:
                    text = self.convert_to_simplified(text)
                
                segment_dict = {
                    "start": segment.start,
                    "end": segment.end,
                    "text": text
                }
                transcript_segments.append(segment_dict)
                full_text += text + " "
            
            print(f"ğŸ­ æ£€æµ‹è¯´è¯äººå˜åŒ–...", file=sys.stderr)
            speakers = self.detect_speaker_change(transcript_segments)
            
            print(f"ğŸ˜Š æ£€æµ‹æƒ…ç»ªæ ‡è®°...", file=sys.stderr)
            
            duration = time.time() - start_time
            
            result = {
                "success": True,
                "file": str(audio_path),
                "text": full_text.strip(),
                "segments": transcript_segments,
                "speakers": speakers,
                "language": info.language,
                "language_probability": info.language_probability,
                "duration": info.duration,
                "processing_time": round(duration, 2),
                "enhanced": True
            }
            
            print(f"âœ… å¢å¼ºè½¬å½•å®Œæˆ: {duration:.1f}ç§’", file=sys.stderr)
            print(f"ğŸ­ æ£€æµ‹åˆ°è¯´è¯äººå˜åŒ–: {len(set(speakers))}ä¸ª", file=sys.stderr)
            
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "file": str(audio_path),
                "error": str(e),
                "text": "",
                "enhanced": False
            }
            print(f"âŒ å¢å¼ºè½¬å½•å¤±è´¥: {e}", file=sys.stderr)
            return error_result

def save_enhanced_transcript_to_file(result, save_dir, file_prefix=None, podcast_title=None, source_url=None):
    """
    ä¿å­˜è½¬å½•æ–‡æœ¬åˆ°æ–‡ä»¶ - ä¿å­˜åŸå§‹ç‰ˆå’Œå¢å¼ºç‰ˆä¸¤ä¸ªæ–‡ä»¶
    """
    try:
        save_path = Path(save_dir)
        save_path.mkdir(parents=True, exist_ok=True)
        saved_files = []
        
        # åˆ›å»ºè½¬å½•å™¨å®ä¾‹æ¥æ ¼å¼åŒ–å†…å®¹
        transcriber = EnhancedWhisperTranscriber()
        
        # 1. ä¿å­˜åŸå§‹è½¬å½•æ–‡ä»¶ï¼ˆçº¯å‡€ç‰ˆæœ¬ï¼‰
        if file_prefix:
            raw_filename = f"{file_prefix}_raw_transcript.md"
        else:
            timestamp = int(time.time())
            raw_filename = f"raw_transcript_{timestamp}.md"
            
        raw_file_path = save_path / raw_filename
        raw_markdown_content = transcriber.format_raw_transcript(
            result['segments'], 
            podcast_title
        )
        
        # æ·»åŠ æ¥æºé“¾æ¥åˆ°åŸå§‹ç‰ˆæœ¬
        if source_url:
            raw_markdown_content += f"\n\n---\n\n**æ¥æº**: {source_url}\n"
        
        with open(raw_file_path, 'w', encoding='utf-8') as f:
            f.write(raw_markdown_content)
        
        raw_file_size = raw_file_path.stat().st_size
        saved_files.append({
            "type": "raw_transcript",
            "filename": raw_filename,
            "path": str(raw_file_path),
            "size": raw_file_size
        })
        print(f"ğŸ“„ åŸå§‹è½¬å½•æ–‡æœ¬å·²ä¿å­˜: {raw_file_path} ({raw_file_size/1024:.1f}KB)", file=sys.stderr)
        
        # 2. ä¿å­˜å¢å¼ºè½¬å½•æ–‡ä»¶ï¼ˆå¦‚æœæœ‰å¢å¼ºåŠŸèƒ½ï¼‰
        if result.get('enhanced') and 'speakers' in result:
            if file_prefix:
                enhanced_filename = f"{file_prefix}_enhanced_transcript.md"
            else:
                enhanced_filename = f"enhanced_transcript_{timestamp}.md"
            
            enhanced_file_path = save_path / enhanced_filename
            enhanced_markdown_content = transcriber.format_transcript_with_speakers_and_emotions(
                result['segments'], 
                result['speakers'], 
                podcast_title
            )
            
            # æ·»åŠ æ¥æºé“¾æ¥åˆ°å¢å¼ºç‰ˆæœ¬
            if source_url:
                enhanced_markdown_content += f"\n\n---\n\n**æ¥æº**: {source_url}\n"
            
            with open(enhanced_file_path, 'w', encoding='utf-8') as f:
                f.write(enhanced_markdown_content)
            
            enhanced_file_size = enhanced_file_path.stat().st_size
            saved_files.append({
                "type": "enhanced_transcript",
                "filename": enhanced_filename,
                "path": str(enhanced_file_path),
                "size": enhanced_file_size
            })
            print(f"ğŸ“„ å¢å¼ºè½¬å½•æ–‡æœ¬å·²ä¿å­˜: {enhanced_file_path} ({enhanced_file_size/1024:.1f}KB)", file=sys.stderr)
        
        return saved_files
        
    except Exception as e:
        print(f"âŒ ä¿å­˜è½¬å½•æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
        return []

def main():
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆæœ¬åœ°Faster-WhisperéŸ³é¢‘è½¬å½•")
    parser.add_argument("files", nargs="+", help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", default="base", 
                       choices=["tiny", "base", "small", "medium", "large-v3"],
                       help="Whisperæ¨¡å‹å¤§å° (é»˜è®¤: base)")
    parser.add_argument("--language", help="æŒ‡å®šè¯­è¨€ä»£ç  (å¦‚: zh, en)")
    parser.add_argument("--device", default="cpu", 
                       choices=["cpu", "cuda"], help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--compute-type", default="int8",
                       choices=["int8", "int16", "float16", "float32"],
                       help="è®¡ç®—ç²¾åº¦")
    parser.add_argument("--output", help="è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--save-transcript", help="ç›´æ¥ä¿å­˜è½¬å½•æ–‡æœ¬åˆ°æŒ‡å®šç›®å½•")
    parser.add_argument("--file-prefix", help="ä¿å­˜æ–‡ä»¶çš„å‰ç¼€åç§°")
    parser.add_argument("--source-url", help="æ’­å®¢æ¥æºé“¾æ¥")
    parser.add_argument("--podcast-title", help="æ’­å®¢æ ‡é¢˜")
    parser.add_argument("--enhanced", action="store_true", help="å¯ç”¨å¢å¼ºæ¨¡å¼ï¼ˆè¯´è¯äººåˆ†ç¦»+æƒ…ç»ªæ£€æµ‹ï¼‰")
    
    args = parser.parse_args()
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    audio_files = []
    for file_path in args.files:
        path = Path(file_path)
        if not path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", file=sys.stderr)
            sys.exit(1)
        audio_files.append(str(path.absolute()))
    
    try:
        # åˆå§‹åŒ–è½¬å½•å™¨
        if args.enhanced:
            print("ğŸš€ å¯åŠ¨å¢å¼ºè½¬å½•æ¨¡å¼", file=sys.stderr)
            transcriber = EnhancedWhisperTranscriber(
                model_size=args.model,
                device=args.device,
                compute_type=args.compute_type.replace("-", "_")
            )
            
            # ä½¿ç”¨å¢å¼ºè½¬å½•
            if len(audio_files) == 1:
                result = transcriber.transcribe_file_enhanced(audio_files[0], args.language)
            else:
                # æ‰¹é‡å¤„ç†ï¼ˆæš‚æ—¶ä½¿ç”¨æ™®é€šæ¨¡å¼ï¼‰
                print("âš ï¸ æ‰¹é‡æ¨¡å¼æš‚ä¸æ”¯æŒå¢å¼ºåŠŸèƒ½ï¼Œä½¿ç”¨æ™®é€šè½¬å½•", file=sys.stderr)
                from whisper_transcribe import LocalWhisperTranscriber
                basic_transcriber = LocalWhisperTranscriber(args.model, args.device, args.compute_type.replace("-", "_"))
                result = basic_transcriber.transcribe_multiple(audio_files, args.language)
        else:
            # ä½¿ç”¨æ™®é€šè½¬å½•
            from whisper_transcribe import LocalWhisperTranscriber
            transcriber = LocalWhisperTranscriber(
                model_size=args.model,
                device=args.device,
                compute_type=args.compute_type.replace("-", "_")
            )
            
            if len(audio_files) == 1:
                result = transcriber.transcribe_file(audio_files[0], args.language)
            else:
                result = transcriber.transcribe_multiple(audio_files, args.language)
        
        # å¤„ç†è½¬å½•æ–‡æœ¬ä¿å­˜
        saved_files = []
        if args.save_transcript and isinstance(result, dict) and result.get('success') and result.get('text'):
            if args.enhanced and result.get('enhanced'):
                # ä¿å­˜å¢å¼ºè½¬å½•ç‰ˆæœ¬ï¼ˆè¿”å›å¤šä¸ªæ–‡ä»¶ï¼‰
                file_infos = save_enhanced_transcript_to_file(
                    result=result,
                    save_dir=args.save_transcript,
                    file_prefix=args.file_prefix,
                    podcast_title=args.podcast_title,
                    source_url=args.source_url
                )
                if file_infos:
                    saved_files.extend(file_infos)
            else:
                # ä½¿ç”¨åŸæœ‰ä¿å­˜æ–¹æ³•
                from whisper_transcribe import save_transcript_to_file
                file_info = save_transcript_to_file(
                    transcript_text=result['text'],
                    save_dir=args.save_transcript,
                    file_prefix=args.file_prefix,
                    original_filename=audio_files[0] if len(audio_files) == 1 else None,
                    source_url=args.source_url,
                    podcast_title=args.podcast_title
                )
                if file_info:
                    saved_files.append(file_info)
        
        # åœ¨ç»“æœä¸­æ·»åŠ ä¿å­˜çš„æ–‡ä»¶ä¿¡æ¯
        if isinstance(result, dict):
            result['savedFiles'] = saved_files
        
        # è¾“å‡ºç»“æœ
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}", file=sys.stderr)
        else:
            # è¾“å‡ºåˆ°stdout
            print(json.dumps(result, ensure_ascii=False))
    
    except KeyboardInterrupt:
        print("\nâš ï¸ è½¬å½•è¢«ç”¨æˆ·ä¸­æ–­", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()