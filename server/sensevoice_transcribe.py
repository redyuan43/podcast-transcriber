#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SenseVoice è½¬å½•è„šæœ¬ - é«˜æ•ˆéŸ³é¢‘è½¬æ–‡å­—
æ”¯æŒå¤šè¯­è¨€ã€æƒ…æ„Ÿè¯†åˆ«ã€éŸ³é¢‘äº‹ä»¶æ£€æµ‹
"""

import sys
import json
import os
import argparse
import time
from pathlib import Path
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
from modelscope import snapshot_download

# è®¾ç½®ç¼“å­˜ç›®å½•
cache_dir = os.path.expanduser("~/.cache/funasr")
os.makedirs(cache_dir, exist_ok=True)

def download_model():
    """ä¸‹è½½ SenseVoice æ¨¡å‹"""
    try:
        import contextlib
        from io import StringIO

        # æ•è·æ¨¡å‹ä¸‹è½½çš„stdoutè¾“å‡º
        f = StringIO()
        with contextlib.redirect_stdout(f):
            model_dir = snapshot_download(
                "iic/SenseVoiceSmall",
                cache_dir=cache_dir
            )

        # å°†ä¸‹è½½ä¿¡æ¯è¾“å‡ºåˆ°stderr
        download_info = f.getvalue()
        if download_info.strip():
            print(f"ğŸ“¦ æ¨¡å‹ä¸‹è½½ä¿¡æ¯: {download_info.strip()}", file=sys.stderr)

        return model_dir
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}", file=sys.stderr)
        # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç¼“å­˜
        local_model = os.path.join(cache_dir, "hub", "models--iic--SenseVoiceSmall")
        if os.path.exists(local_model):
            print(f"ğŸ“¦ ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ¨¡å‹", file=sys.stderr)
            return local_model
        raise

def format_timestamp(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º HH:MM:SS æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    return f"{hours:02d}:{minutes:02d}:{secs:02d}"

def transcribe_audio(audio_path, language="auto", use_itn=True, batch_size=64):
    """
    ä½¿ç”¨ SenseVoice è½¬å½•éŸ³é¢‘

    å‚æ•°:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        language: è¯­è¨€è®¾ç½® (auto/zh/en/yue/ja/ko)
        use_itn: æ˜¯å¦ä½¿ç”¨æ•°å­—è§„èŒƒåŒ– (ITN)
        batch_size: æ‰¹å¤„ç†å¤§å°
    """
    start_time = time.time()

    print(f"ğŸ¤ å¼€å§‹è½¬å½•: {os.path.basename(audio_path)}", file=sys.stderr)
    print(f"ğŸ“Š é…ç½®: è¯­è¨€={language}, ITN={use_itn}, æ‰¹å¤§å°={batch_size}", file=sys.stderr)

    try:
        # ä¸‹è½½æˆ–è·å–æ¨¡å‹è·¯å¾„
        model_dir = download_model()

        # é€‰æ‹©æœ€ä½³GPUè®¾å¤‡
        import torch
        if torch.cuda.is_available():
            # é€‰æ‹©æ˜¾å­˜æœ€å¤šçš„GPU
            gpu_count = torch.cuda.device_count()
            best_gpu = 0
            if gpu_count > 1:
                max_memory = 0
                for i in range(gpu_count):
                    memory = torch.cuda.get_device_properties(i).total_memory
                    if memory > max_memory:
                        max_memory = memory
                        best_gpu = i
            device = f"cuda:{best_gpu}"
            print(f"ğŸ¯ ä½¿ç”¨GPU: {torch.cuda.get_device_name(best_gpu)} (è®¾å¤‡ {best_gpu})", file=sys.stderr)
        else:
            device = "cpu"
            print(f"âš ï¸ æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPU", file=sys.stderr)

        # åˆå§‹åŒ– SenseVoice æ¨¡å‹ï¼ˆä¼˜åŒ–é…ç½®ï¼‰
        print(f"ğŸ”„ åŠ è½½ SenseVoice æ¨¡å‹åˆ° {device}...", file=sys.stderr)

        # æ•è·æ¨¡å‹åˆå§‹åŒ–çš„è¾“å‡º
        import contextlib
        from io import StringIO
        f2 = StringIO()
        with contextlib.redirect_stdout(f2):
            model = AutoModel(
                model=model_dir,
                trust_remote_code=True,
                remote_code="./model.py",
                vad_model="fsmn-vad",
                vad_kwargs={
                    "max_single_segment_time": 30000,
                    "max_end_silence_time": 800,  # å‡å°‘é™éŸ³æ£€æµ‹æ—¶é—´
                },
                device=device
            )

        # å°†æ¨¡å‹åˆå§‹åŒ–ä¿¡æ¯è¾“å‡ºåˆ°stderr
        init_info = f2.getvalue()
        if init_info.strip():
            print(f"ğŸ—ï¸ æ¨¡å‹åˆå§‹åŒ–: {init_info.strip()}", file=sys.stderr)

        # æ‰§è¡Œè½¬å½•ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
        print(f"ğŸ¯ æ­£åœ¨è½¬å½•...", file=sys.stderr)
        res = model.generate(
            input=audio_path,
            cache={},
            language=language,
            use_itn=use_itn,
            batch_size_s=batch_size,
            merge_vad=True,
            merge_length_s=30,  # å¢åŠ åˆå¹¶é•¿åº¦ï¼Œå‡å°‘ç‰‡æ®µæ•°é‡
            pred_timestamp=True,  # å¯ç”¨æ—¶é—´æˆ³é¢„æµ‹
        )

        # å¤„ç†ç»“æœ
        if not res or len(res) == 0:
            raise ValueError("è½¬å½•ç»“æœä¸ºç©º")

        # æå–è½¬å½•æ–‡æœ¬å’Œç‰‡æ®µ
        full_text = res[0]["text"] if isinstance(res[0], dict) else res[0].get("text", "")

        # åº”ç”¨åå¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if use_itn:
            full_text = rich_transcription_postprocess(full_text)

        # æ£€æµ‹è¯­è¨€
        detected_language = res[0].get("language", language if language != "auto" else "zh")

        # æå–æƒ…æ„Ÿä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        emotion = res[0].get("emotion", None)
        events = res[0].get("event", [])

        # æ„å»ºç‰‡æ®µä¿¡æ¯ï¼ˆSenseVoice å¯èƒ½è¿”å› VAD åˆ†å‰²çš„ç‰‡æ®µï¼‰
        segments = []
        if "segments" in res[0]:
            for seg in res[0]["segments"]:
                segment = {
                    "start": seg.get("start", 0),
                    "end": seg.get("end", 0),
                    "text": seg.get("text", ""),
                }
                if "speaker" in seg:
                    segment["speaker"] = seg["speaker"]
                segments.append(segment)
        else:
            # å¦‚æœæ²¡æœ‰ç‰‡æ®µä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ªå®Œæ•´ç‰‡æ®µ
            segments = [{
                "start": 0,
                "end": len(full_text) * 0.17,  # ä¼°ç®—æ—¶é•¿ï¼ˆæ¯å­—ç¬¦çº¦0.17ç§’ï¼‰
                "text": full_text
            }]

        elapsed_time = time.time() - start_time
        print(f"âœ… è½¬å½•å®Œæˆ: {len(full_text)} å­—ç¬¦, è€—æ—¶ {elapsed_time:.2f} ç§’", file=sys.stderr)

        # æ„å»ºç»“æœ
        result = {
            "success": True,
            "text": full_text,
            "segments": segments,
            "language": detected_language,
            "duration": elapsed_time,
            "model": "SenseVoiceSmall",
            "stats": {
                "total_characters": len(full_text),
                "total_segments": len(segments),
                "processing_time": elapsed_time,
                "audio_file": os.path.basename(audio_path)
            }
        }

        # æ·»åŠ é¢å¤–ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if emotion:
            result["emotion"] = emotion
        if events:
            result["events"] = events

        return result

    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥: {str(e)}", file=sys.stderr)
        return {
            "success": False,
            "error": str(e),
            "text": "",
            "segments": []
        }

def save_transcript_files(result, output_dir, file_prefix, podcast_title):
    """ä¿å­˜è½¬å½•ç»“æœåˆ°æ–‡ä»¶"""
    saved_files = []

    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)

        # ä¿å­˜çº¯æ–‡æœ¬æ–‡ä»¶
        txt_file = os.path.join(output_dir, f"{file_prefix}_transcript.txt")
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(result["text"])
        saved_files.append(txt_file)
        print(f"ğŸ’¾ ä¿å­˜æ–‡æœ¬: {txt_file}", file=sys.stderr)

        # ä¿å­˜ JSON æ ¼å¼ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
        json_file = os.path.join(output_dir, f"{file_prefix}_transcript.json")
        json_data = {
            "title": podcast_title,
            "model": result.get("model", "SenseVoiceSmall"),
            "language": result.get("language", "auto"),
            "duration": result.get("duration", 0),
            "text": result["text"],
            "segments": result["segments"],
            "stats": result.get("stats", {})
        }

        # æ·»åŠ é¢å¤–ä¿¡æ¯
        if "emotion" in result:
            json_data["emotion"] = result["emotion"]
        if "events" in result:
            json_data["events"] = result["events"]

        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        saved_files.append(json_file)
        print(f"ğŸ’¾ ä¿å­˜JSON: {json_file}", file=sys.stderr)

        # ä¿å­˜ Markdown æ ¼å¼ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        md_file = os.path.join(output_dir, f"{file_prefix}_transcript.md")
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(f"# {podcast_title}\n\n")
            f.write(f"**æ¨¡å‹**: {result.get('model', 'SenseVoiceSmall')}  \n")
            f.write(f"**è¯­è¨€**: {result.get('language', 'auto')}  \n")
            f.write(f"**å¤„ç†æ—¶é—´**: {result.get('duration', 0):.2f} ç§’  \n\n")

            if "emotion" in result:
                f.write(f"**æƒ…æ„Ÿ**: {result['emotion']}  \n\n")

            f.write("## è½¬å½•å†…å®¹\n\n")

            # æŒ‰æ®µè½è¾“å‡º
            if result["segments"]:
                for seg in result["segments"]:
                    timestamp = format_timestamp(seg["start"])
                    text = seg["text"].strip()
                    if text:
                        f.write(f"**[{timestamp}]** {text}\n\n")
            else:
                f.write(result["text"])

        saved_files.append(md_file)
        print(f"ğŸ’¾ ä¿å­˜Markdown: {md_file}", file=sys.stderr)

        return saved_files

    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}", file=sys.stderr)
        return saved_files

def main():
    parser = argparse.ArgumentParser(description='SenseVoice éŸ³é¢‘è½¬å½•å·¥å…·')
    parser.add_argument('audio_file', help='éŸ³é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--language', default='auto',
                      choices=['auto', 'zh', 'en', 'yue', 'ja', 'ko'],
                      help='è¯­è¨€è®¾ç½® (é»˜è®¤: auto)')
    parser.add_argument('--no-itn', action='store_true',
                      help='ç¦ç”¨æ•°å­—è§„èŒƒåŒ–ï¼ˆITNï¼‰')
    parser.add_argument('--batch-size', type=int, default=64,
                      help='æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤: 64ï¼‰')
    parser.add_argument('--save-transcript', help='ä¿å­˜è½¬å½•æ–‡æœ¬çš„ç›®å½•')
    parser.add_argument('--file-prefix', default='sensevoice',
                      help='ä¿å­˜æ–‡ä»¶çš„å‰ç¼€')
    parser.add_argument('--podcast-title', default='Untitled',
                      help='æ’­å®¢æ ‡é¢˜')
    parser.add_argument('--source-url', default='',
                      help='æºURLï¼ˆå¯é€‰ï¼‰')

    args = parser.parse_args()

    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.audio_file):
        print(json.dumps({
            "success": False,
            "error": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.audio_file}",
            "text": "",
            "segments": []
        }, ensure_ascii=False))
        sys.exit(1)

    # æ‰§è¡Œè½¬å½•
    result = transcribe_audio(
        args.audio_file,
        language=args.language,
        use_itn=not args.no_itn,
        batch_size=args.batch_size
    )

    # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.save_transcript and result["success"]:
        saved_files = save_transcript_files(
            result,
            args.save_transcript,
            args.file_prefix,
            args.podcast_title
        )
        result["savedFiles"] = saved_files

    # è¾“å‡ºç»“æœï¼ˆJSONæ ¼å¼ï¼‰
    print(json.dumps(result, ensure_ascii=False, indent=2))

    # è¿”å›çŠ¶æ€ç 
    sys.exit(0 if result["success"] else 1)

if __name__ == "__main__":
    main()