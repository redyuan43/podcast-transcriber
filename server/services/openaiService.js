const OpenAI = require('openai');
const fs = require('fs');
const path = require('path');
const { exec } = require('child_process');
const { promisify } = require('util');

const execAsync = promisify(exec);

// æœ¬åœ°Whisperè½¬å½•é…ç½®
const WHISPER_MODEL = process.env.WHISPER_MODEL || 'base'; // Whisperæ¨¡å‹å¤§å°
console.log(`ğŸ¤ è½¬å½•æ¨¡å¼: æœ¬åœ°Faster-Whisper`);

// åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆç”¨äºæ€»ç»“å’Œæ–‡æœ¬ä¼˜åŒ–ï¼‰
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    baseURL: process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1',
    timeout: 300000, // 5åˆ†é’Ÿè¶…æ—¶ï¼ˆéŸ³é¢‘è½¬å½•éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
    maxRetries: 0  // ç¦ç”¨è‡ªåŠ¨é‡è¯•ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å¤„ç†
});

/**
 * å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ˆå•ä¸ªæˆ–å¤šä¸ªç‰‡æ®µï¼‰
 * @param {Array|string} audioFiles - éŸ³é¢‘æ–‡ä»¶è·¯å¾„æ•°ç»„æˆ–å•ä¸ªè·¯å¾„
 * @param {boolean} shouldSummarize - æ˜¯å¦éœ€è¦æ€»ç»“
 * @param {string} outputLanguage - è¾“å‡ºè¯­è¨€
 * @returns {Promise<Object>} - å¤„ç†ç»“æœ
 */
async function processAudioWithOpenAI(audioFiles, shouldSummarize = false, outputLanguage = 'zh') {
    try {
        console.log(`ğŸ¤– å¼€å§‹éŸ³é¢‘å¤„ç† - OpenAI`);
        
        // ç¡®ä¿ audioFiles æ˜¯æ•°ç»„
        const files = Array.isArray(audioFiles) ? audioFiles : [audioFiles];
        console.log(`ğŸ“„ å¤„ç†æ–‡ä»¶æ•°é‡: ${files.length}`);

        let transcript = '';

        if (files.length === 1) {
            // å•æ–‡ä»¶å¤„ç†
            console.log(`ğŸµ å•æ–‡ä»¶å¤„ç†æ¨¡å¼`);
            transcript = await transcribeAudio(files[0], true); // è‡ªåŠ¨æ£€æµ‹è¯­è¨€
        } else {
            // å¤šæ–‡ä»¶å¹¶å‘å¤„ç†
            console.log(`ğŸ¬ å¤šæ–‡ä»¶å¹¶å‘å¤„ç†æ¨¡å¼`);
            transcript = await transcribeMultipleAudios(files, outputLanguage);
        }

        let result = {
            transcript: transcript,
            language: outputLanguage
        };

        if (shouldSummarize) {
            console.log(`ğŸ“ å¼€å§‹ç”Ÿæˆæ€»ç»“...`);
            const summary = await generateSummary(transcript, outputLanguage);
            result.summary = summary;
        }

        console.log(`âœ… éŸ³é¢‘å¤„ç†å®Œæˆ`);
        return result;

    } catch (error) {
        console.error('âŒ OpenAIå¤„ç†å¤±è´¥:', error);
        throw error;
    }
}

/**
 * å¹¶å‘è½¬å½•å¤šä¸ªéŸ³é¢‘æ–‡ä»¶å¹¶ä¼˜åŒ–æ‹¼æ¥
 * @param {Array} audioFiles - éŸ³é¢‘æ–‡ä»¶è·¯å¾„æ•°ç»„
 * @param {string} outputLanguage - æ€»ç»“è¾“å‡ºè¯­è¨€ï¼ˆä¸å½±å“è½¬å½•è¯­è¨€ï¼‰
 * @returns {Promise<string>} - ä¼˜åŒ–åçš„å®Œæ•´è½¬å½•æ–‡æœ¬
 */
async function transcribeMultipleAudios(audioFiles, outputLanguage) {
    try {
        console.log(`ğŸ”„ å¼€å§‹ä¸²è¡Œè½¬å½• ${audioFiles.length} ä¸ªéŸ³é¢‘ç‰‡æ®µï¼ˆé¿å…APIè¿‡è½½ï¼‰...`);
        
        // åˆ†æ‰¹å¤„ç†éŸ³é¢‘ç‰‡æ®µï¼Œé¿å…å¹¶å‘è¿‡è½½ï¼Œä½¿ç”¨é‡è¯•æœºåˆ¶
        const batchSize = 1; // æ¯æ‰¹æœ€å¤š1ä¸ªæ–‡ä»¶ - å®Œå…¨ä¸²è¡Œå¤„ç†
        const transcriptions = [];
        
        for (let i = 0; i < audioFiles.length; i += batchSize) {
            const batch = audioFiles.slice(i, i + batchSize);
            console.log(`ğŸ”„ å¤„ç†æ‰¹æ¬¡ ${Math.floor(i/batchSize) + 1}/${Math.ceil(audioFiles.length/batchSize)}: ${batch.length} ä¸ªæ–‡ä»¶`);
            
            const batchPromises = batch.map(async (file, batchIndex) => {
                const index = i + batchIndex;
                let retryCount = 0;
                const maxRetries = 2;
                
                while (retryCount <= maxRetries) {
                    try {
                        console.log(`   ğŸµ å¼€å§‹è½¬å½•ç‰‡æ®µ ${index + 1}/${audioFiles.length}: ${path.basename(file)} ${retryCount > 0 ? `(é‡è¯• ${retryCount})` : ''}`);
                        const result = await transcribeAudio(file, true); // å§‹ç»ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€
                        console.log(`   âœ… ç‰‡æ®µ ${index + 1} è½¬å½•å®Œæˆ (${result.length} å­—ç¬¦)`);
                        return {
                            index,
                            text: result,
                            filename: path.basename(file),
                            success: true
                        };
                    } catch (error) {
                        retryCount++;
                        if (retryCount <= maxRetries) {
                            console.log(`   âš ï¸ ç‰‡æ®µ ${index + 1} è½¬å½•å¤±è´¥ï¼Œå‡†å¤‡é‡è¯• ${retryCount}/${maxRetries}: ${error.message}`);
                            // ç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯• - å¢åŠ å»¶è¿Ÿé˜²æ­¢è¿æ¥é‡ç½®
                            await new Promise(resolve => setTimeout(resolve, 3000 * retryCount));
                        } else {
                            console.error(`   âŒ ç‰‡æ®µ ${index + 1} è½¬å½•æœ€ç»ˆå¤±è´¥:`, error);
                            return {
                                index,
                                text: null, // æ ‡è®°ä¸ºå¤±è´¥ï¼Œä¸æä¾›é”™è¯¯æ–‡æœ¬
                                filename: path.basename(file),
                                success: false,
                                error: error.message
                            };
                        }
                    }
                }
            });
            
            // ç­‰å¾…å½“å‰æ‰¹æ¬¡å®Œæˆ
            const batchResults = await Promise.all(batchPromises);
            transcriptions.push(...batchResults);
            
            // æ‰¹æ¬¡é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…APIå‹åŠ›
            if (i + batchSize < audioFiles.length) {
                console.log(`â³ æ‰¹æ¬¡é—´ä¼‘æ¯5ç§’ï¼Œé¿å…APIè¿‡è½½...`);
                await new Promise(resolve => setTimeout(resolve, 5000));
            }
        }

        // æŒ‰é¡ºåºæ’åˆ—è½¬å½•ç»“æœ
        transcriptions.sort((a, b) => a.index - b.index);
        
        // ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„ç‰‡æ®µ
        const successfulTranscriptions = transcriptions.filter(t => t.success && t.text);
        const failedCount = transcriptions.length - successfulTranscriptions.length;
        
        console.log(`ğŸ“‹ è½¬å½•å®Œæˆç»Ÿè®¡: ${successfulTranscriptions.length}/${transcriptions.length} æˆåŠŸ, ${failedCount} å¤±è´¥`);
        
        if (successfulTranscriptions.length === 0) {
            throw new Error('æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µè½¬å½•éƒ½å¤±è´¥äº†ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®ï¼Œæˆ–ç¨åé‡è¯•ã€‚');
        }
        
        if (failedCount > 0) {
            console.warn(`âš ï¸ ${failedCount} ä¸ªç‰‡æ®µè½¬å½•å¤±è´¥ï¼Œå°†åŸºäº ${successfulTranscriptions.length} ä¸ªæˆåŠŸç‰‡æ®µç»§ç»­å¤„ç†`);
        }
        
        // åªæ‹¼æ¥æˆåŠŸçš„è½¬å½•æ–‡æœ¬
        const rawTranscript = successfulTranscriptions
            .map(t => t.text)
            .join('\n\n');

        console.log(`ğŸ“Š æœ‰æ•ˆè½¬å½•å†…å®¹: ${rawTranscript.length} å­—ç¬¦`);
        
        // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å†…å®¹è¿›è¡Œä¼˜åŒ–
        if (rawTranscript.length < 50) {
            console.warn('âš ï¸ è½¬å½•å†…å®¹å¤ªå°‘ï¼Œè·³è¿‡AIä¼˜åŒ–');
            return rawTranscript;
        }
        
        // ä½¿ç”¨AIä¼˜åŒ–æ‹¼æ¥çš„æ–‡æœ¬
        const optimizedTranscript = await optimizeTranscriptContinuity(rawTranscript, outputLanguage);
        
        console.log(`âœ¨ æ–‡æœ¬ä¼˜åŒ–å®Œæˆ: ${optimizedTranscript.length} å­—ç¬¦`);
        
        return optimizedTranscript;

    } catch (error) {
        console.error('âŒ å¤šæ–‡ä»¶è½¬å½•å¤±è´¥:', error);
        throw error;
    }
}

/**
 * ä½¿ç”¨æœ¬åœ°Faster-Whisperè½¬å½•éŸ³é¢‘
 * @param {string} audioPath - éŸ³é¢‘æ–‡ä»¶è·¯å¾„
 * @param {string} language - è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
 * @returns {Promise<string>} - è½¬å½•æ–‡æœ¬
 */
async function transcribeAudioLocal(audioPath, language = null) {
    try {
        console.log(`ğŸ¤ æœ¬åœ°è½¬å½•: ${path.basename(audioPath)}`);
        
        // æ„å»ºPythonå‘½ä»¤
        const scriptPath = path.join(__dirname, '..', 'whisper_transcribe.py');
        let command = `python3 "${scriptPath}" "${audioPath}" --model ${WHISPER_MODEL}`;
        
        if (language) {
            command += ` --language ${language}`;
        }
        
        console.log(`âš™ï¸ æ‰§è¡Œå‘½ä»¤: ${command}`);
        
        // æ‰§è¡Œè½¬å½•è„šæœ¬
        const { stdout, stderr } = await execAsync(command, {
            maxBuffer: 1024 * 1024 * 10, // 10MBç¼“å†²åŒº
            timeout: 600000 // 10åˆ†é’Ÿè¶…æ—¶
        });
        
        if (stderr && stderr.trim()) {
            console.log(`ğŸ”§ Whisperæ—¥å¿—: ${stderr.trim()}`);
        }
        
        // è§£æJSONç»“æœ
        const result = JSON.parse(stdout);
        
        if (!result.success) {
            throw new Error(result.error || 'æœ¬åœ°è½¬å½•å¤±è´¥');
        }
        
        const transcript = result.text || '';
        console.log(`âœ… æœ¬åœ°è½¬å½•å®Œæˆ: ${transcript.length} å­—ç¬¦`);
        console.log(`ğŸ“Š å¤„ç†æ—¶é—´: ${result.processing_time}ç§’, æ£€æµ‹è¯­è¨€: ${result.language} (${(result.language_probability * 100).toFixed(1)}%)`);
        
        return transcript;
        
    } catch (error) {
        console.error(`âŒ æœ¬åœ°è½¬å½•å¤±è´¥:`, error);
        
        // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        if (error.message.includes('ENOENT')) {
            throw new Error('Python3æˆ–Whisperè„šæœ¬æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥å®‰è£…');
        } else if (error.message.includes('timeout')) {
            throw new Error('æœ¬åœ°è½¬å½•è¶…æ—¶ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°');
        } else if (error.message.includes('JSON')) {
            throw new Error('æœ¬åœ°è½¬å½•è¾“å‡ºæ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥è„šæœ¬');
        } else {
            throw new Error(`æœ¬åœ°è½¬å½•å¤±è´¥: ${error.message}`);
        }
    }
}

/**
 * è½¬å½•å•ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆæœ¬åœ°Faster-Whisperï¼‰
 * @param {string} audioPath - éŸ³é¢‘æ–‡ä»¶è·¯å¾„
 * @param {string} autoDetect - æ˜¯å¦è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼ˆè½¬å½•å§‹ç»ˆä¿æŒåŸè¯­è¨€ï¼‰
 * @returns {Promise<string>} - è½¬å½•æ–‡æœ¬
 */
async function transcribeAudio(audioPath, autoDetect = true) {
    return await transcribeAudioLocal(audioPath, autoDetect ? null : 'zh');
}



/**
 * ä¼˜åŒ–è½¬å½•æ–‡æœ¬çš„è¿ç»­æ€§å’Œæµç•…æ€§
 * @param {string} rawTranscript - åŸå§‹æ‹¼æ¥çš„è½¬å½•æ–‡æœ¬
 * @param {string} outputLanguage - è¾“å‡ºè¯­è¨€ï¼ˆä»…å½±å“ä¼˜åŒ–æç¤ºè¯­è¨€ï¼Œä¸æ”¹å˜å†…å®¹è¯­è¨€ï¼‰
 * @returns {Promise<string>} - ä¼˜åŒ–åçš„è½¬å½•æ–‡æœ¬
 */
async function optimizeTranscriptContinuity(rawTranscript, outputLanguage) {
    try {
        console.log(`ğŸ”§ å¼€å§‹ä¼˜åŒ–æ–‡æœ¬è¿ç»­æ€§...`);
        
        // æ£€æŸ¥æ–‡æœ¬è´¨é‡ï¼Œé¿å…å¤„ç†é”™è¯¯ä¿¡æ¯
        if (rawTranscript.includes('[è½¬å½•å¤±è´¥') || rawTranscript.includes('error') || rawTranscript.length < 20) {
            console.log('ğŸ“„ è·³è¿‡ä¼˜åŒ–ï¼šæ–‡æœ¬è´¨é‡ä¸è¶³æˆ–åŒ…å«é”™è¯¯ä¿¡æ¯');
            return rawTranscript;
        }
        
        const systemPrompt = outputLanguage === 'zh' 
            ? `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘åŠ©æ‰‹ã€‚è¯·ä¼˜åŒ–ä»¥ä¸‹è½¬å½•æ–‡æœ¬ï¼Œä½¿å…¶æ›´æµç•…è‡ªç„¶ï¼š

ä»»åŠ¡è¦æ±‚ï¼š
1. ä¿æŒåŸæ–‡çš„å®Œæ•´æ„æ€å’Œè¯­è¨€ï¼Œä¸è¦æ”¹å˜æˆ–åˆ å‡å†…å®¹
2. ä¼˜åŒ–ç‰‡æ®µé—´çš„è¡”æ¥ï¼Œä½¿è¯­å¥æ›´è¿è´¯
3. æ¸…ç†å¤šä½™çš„è¯­æ°”è¯ï¼ˆå—¯ã€å•Šã€é‚£ä¸ªç­‰ï¼‰ï¼Œä½†ä¿ç•™å¿…è¦çš„è¯­æ°”è¡¨è¾¾
4. ä¿®æ­£æ˜æ˜¾çš„æ–­å¥é”™è¯¯
5. ä¿æŒè¯´è¯è€…çš„åŸå§‹è¯­è¨€é£æ ¼å’Œè¡¨è¾¾ä¹ æƒ¯
6. ä¸è¦ç¿»è¯‘æˆ–æ”¹å˜åŸæ–‡è¯­è¨€
7. ä¸è¦æ·»åŠ åŸæ–‡ä¸­æ²¡æœ‰çš„ä¿¡æ¯

è¯·ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„æ–‡æœ¬ï¼Œä¿æŒåŸè¯­è¨€ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡æ³¨ã€‚`

            : `You are a professional text editing assistant. Please optimize the following transcript to make it more fluent and natural:

Requirements:
1. Maintain the complete meaning and language of the original text, do not change or remove content
2. Optimize transitions between segments for better coherence
3. Clean up excessive filler words (um, uh, like, etc.) while keeping necessary expressions
4. Fix obvious sentence breaks
5. Maintain the speaker's original language style and expression habits
6. Do not translate or change the original language
7. Do not add information not present in the original text

Please output the optimized text directly in the original language without any explanations or annotations.`;

        const response = await openai.chat.completions.create({
            model: "gpt-4",
            messages: [
                { role: "system", content: systemPrompt },
                { role: "user", content: rawTranscript }
            ],
            temperature: 0.3,
            max_tokens: Math.min(4000, Math.floor(rawTranscript.length * 1.2))
        });

        const optimizedText = response.choices[0].message.content.trim();
        console.log(`âœ¨ æ–‡æœ¬ä¼˜åŒ–å®Œæˆ`);
        
        return optimizedText;

    } catch (error) {
        console.error('âŒ æ–‡æœ¬ä¼˜åŒ–å¤±è´¥:', error);
        console.log('ğŸ“„ è¿”å›åŸå§‹æ‹¼æ¥æ–‡æœ¬');
        return rawTranscript; // å¤±è´¥æ—¶è¿”å›åŸå§‹æ–‡æœ¬
    }
}

/**
 * ç”ŸæˆéŸ³é¢‘å†…å®¹æ€»ç»“
 * @param {string} transcript - è½¬å½•æ–‡æœ¬
 * @param {string} outputLanguage - è¾“å‡ºè¯­è¨€
 * @returns {Promise<string>} - æ€»ç»“æ–‡æœ¬
 */
async function generateSummary(transcript, outputLanguage = 'zh') {
    try {
        console.log(`ğŸ“‹ ç”Ÿæˆæ€»ç»“ (${outputLanguage})...`);
        
        const systemPrompt = outputLanguage === 'zh'
            ? `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ€»ç»“åŠ©æ‰‹ã€‚è¯·ä¸ºä»¥ä¸‹éŸ³é¢‘è½¬å½•å†…å®¹ç”Ÿæˆä¸€ä¸ªå…¨é¢ã€ç»“æ„åŒ–çš„æ€»ç»“ï¼š

æ€»ç»“è¦æ±‚ï¼š
1. æå–ä¸»è¦è¯é¢˜å’Œå…³é”®ä¿¡æ¯
2. ä¿æŒé€»è¾‘ç»“æ„æ¸…æ™°
3. åŒ…å«é‡è¦çš„è§‚ç‚¹ã€æ•°æ®å’Œç»“è®º
4. ä½¿ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€
5. é€‚å½“ä¿ç•™è¯´è¯è€…çš„è¡¨è¾¾é£æ ¼
6. æ€»ç»“é•¿åº¦çº¦ä¸ºåŸæ–‡çš„20-30%

è¯·ç”Ÿæˆç»“æ„åŒ–çš„æ€»ç»“ï¼ŒåŒ…å«è¦ç‚¹å’Œå…³é”®å†…å®¹ã€‚`

            : `You are a professional content summarization assistant. Please generate a comprehensive, structured summary for the following audio transcript:

Summary requirements:
1. Extract main topics and key information
2. Maintain clear logical structure
3. Include important viewpoints, data, and conclusions
4. Use concise and clear language
5. Appropriately retain the speaker's expression style
6. Summary length should be about 20-30% of the original text

Please generate a structured summary with key points and essential content.`;

        const response = await openai.chat.completions.create({
            model: "gpt-4",
            messages: [
                { role: "system", content: systemPrompt },
                { role: "user", content: transcript }
            ],
            temperature: 0.5,
            max_tokens: Math.min(2000, Math.floor(transcript.length * 0.4))
        });

        const summary = response.choices[0].message.content.trim();
        console.log(`ğŸ“„ æ€»ç»“ç”Ÿæˆå®Œæˆ: ${summary.length} å­—ç¬¦`);
        
        return summary;

    } catch (error) {
        console.error('âŒ æ€»ç»“ç”Ÿæˆå¤±è´¥:', error);
        throw new Error(`æ€»ç»“ç”Ÿæˆå¤±è´¥: ${error.message}`);
    }
}

module.exports = {
    processAudioWithOpenAI,
    transcribeAudio,
    transcribeAudioLocal,
    transcribeMultipleAudios,
    optimizeTranscriptContinuity,
    generateSummary
};