#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
PyAnnote è¯´è¯äººåˆ†ç¦»æ¨¡å—
ä½¿ç”¨ pyannote.audio è¿›è¡Œä¸“ä¸šçº§è¯´è¯äººåˆ†å‰²
"""

import sys
import json
import os
import argparse
import time
from pathlib import Path
import torch
from pyannote.audio import Pipeline
import warnings

# ç¦ç”¨æ‰€æœ‰è­¦å‘Šè¾“å‡ºåˆ° stdout
warnings.filterwarnings("ignore")

# é‡å®šå‘æ ‡å‡†è¾“å‡ºï¼Œç¡®ä¿åªæœ‰JSONè¾“å‡ºåˆ°stdout
import contextlib
import io

def format_timestamp(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º HH:MM:SS.mmm æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = seconds % 60
    return f"{hours:02d}:{minutes:02d}:{secs:06.3f}"

def diarize_audio(audio_path, num_speakers=None, min_speakers=1, max_speakers=10):
    """
    ä½¿ç”¨ pyannote.audio è¿›è¡Œè¯´è¯äººåˆ†ç¦»

    å‚æ•°:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        num_speakers: æŒ‡å®šè¯´è¯äººæ•°é‡ï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ï¼‰
        min_speakers: æœ€å°‘è¯´è¯äººæ•°é‡
        max_speakers: æœ€å¤šè¯´è¯äººæ•°é‡
    """
    start_time = time.time()

    print(f"ğŸ¤ å¼€å§‹è¯´è¯äººåˆ†ç¦»: {os.path.basename(audio_path)}", file=sys.stderr)

    # æ•è·å’Œé‡å®šå‘æ‰€æœ‰éå…³é”®çš„è¾“å‡º
    captured_output = io.StringIO()

    try:
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}", file=sys.stderr)

        # åˆå§‹åŒ–è¯´è¯äººåˆ†ç¦»ç®¡é“
        print(f"ğŸ”„ åŠ è½½ pyannote.audio ç®¡é“...", file=sys.stderr)

        # é‡å®šå‘stdouté¿å…æ¨¡å‹è¾“å‡ºæ±¡æŸ“
        with contextlib.redirect_stdout(captured_output):
            # ä½¿ç”¨é¢„è®­ç»ƒçš„è¯´è¯äººåˆ†ç¦»æ¨¡å‹
            token = os.getenv('HF_TOKEN') or True

            # å°è¯•åŠ è½½æ¨¡å‹ï¼ŒæŒ‰ä¼˜å…ˆçº§ä¾æ¬¡å°è¯•
            models_to_try = [
                "pyannote/speaker-diarization@2022.07",  # å…ˆå°è¯•ç¨³å®šç‰ˆæœ¬
                "pyannote/speaker-diarization-3.1"       # ç„¶åå°è¯•æœ€æ–°ç‰ˆæœ¬
            ]

            pipeline = None
            for model_name in models_to_try:
                try:
                    print(f"ğŸ“¡ å°è¯•åŠ è½½æ¨¡å‹: {model_name}", file=sys.stderr)
                    pipeline = Pipeline.from_pretrained(model_name, use_auth_token=token)
                    print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_name}", file=sys.stderr)
                    break
                except Exception as e:
                    print(f"âŒ æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥: {e}", file=sys.stderr)
                    continue

            if pipeline is None:
                raise Exception("æ‰€æœ‰ PyAnnote æ¨¡å‹åŠ è½½å¤±è´¥ã€‚è¯·ç¡®ä¿å·²æ¥å—æ‰€æœ‰å¿…è¦çš„æ¨¡å‹æ¡æ¬¾å¹¶æ­£ç¡®è®¤è¯ã€‚")

            # è®¾ç½®è®¾å¤‡
            if device == "cuda":
                pipeline.to(torch.device("cuda"))

        print(f"âœ… ç®¡é“åŠ è½½å®Œæˆ", file=sys.stderr)

        # é…ç½®è¯´è¯äººæ•°é‡å‚æ•°
        if num_speakers is not None:
            print(f"ğŸ¯ æŒ‡å®šè¯´è¯äººæ•°é‡: {num_speakers}", file=sys.stderr)
            diarization = pipeline(
                audio_path,
                num_speakers=num_speakers
            )
        else:
            print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹è¯´è¯äºº (èŒƒå›´: {min_speakers}-{max_speakers})", file=sys.stderr)
            diarization = pipeline(
                audio_path,
                min_speakers=min_speakers,
                max_speakers=max_speakers
            )

        # å¤„ç†åˆ†ç¦»ç»“æœ
        segments = []
        speaker_labels = set()

        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segment = {
                "start": float(turn.start),
                "end": float(turn.end),
                "duration": float(turn.end - turn.start),
                "speaker": speaker,
                "start_formatted": format_timestamp(turn.start),
                "end_formatted": format_timestamp(turn.end)
            }
            segments.append(segment)
            speaker_labels.add(speaker)

        # æŒ‰æ—¶é—´æ’åº
        segments.sort(key=lambda x: x["start"])

        elapsed_time = time.time() - start_time

        print(f"âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆ!", file=sys.stderr)
        print(f"ğŸ“Š æ£€æµ‹åˆ° {len(speaker_labels)} ä¸ªè¯´è¯äºº: {', '.join(sorted(speaker_labels))}", file=sys.stderr)
        print(f"ğŸ¬ åˆ†å‰²ä¸º {len(segments)} ä¸ªç‰‡æ®µ", file=sys.stderr)
        print(f"â±ï¸ å¤„ç†æ—¶é—´: {elapsed_time:.2f} ç§’", file=sys.stderr)

        # æ„å»ºç»“æœ
        result = {
            "success": True,
            "audio_file": os.path.basename(audio_path),
            "speakers": sorted(list(speaker_labels)),
            "num_speakers": len(speaker_labels),
            "segments": segments,
            "processing_time": elapsed_time,
            "stats": {
                "total_segments": len(segments),
                "total_speakers": len(speaker_labels),
                "audio_duration": max([seg["end"] for seg in segments]) if segments else 0,
                "avg_segment_duration": sum([seg["duration"] for seg in segments]) / len(segments) if segments else 0
            }
        }

        return result

    except Exception as e:
        error_msg = str(e)
        print(f"âŒ è¯´è¯äººåˆ†ç¦»å¤±è´¥: {error_msg}", file=sys.stderr)

        # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
        if "auth" in error_msg.lower() or "token" in error_msg.lower():
            print("ğŸ’¡ æç¤º: éœ€è¦ HuggingFace token æ¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹", file=sys.stderr)
            print("   1. è®¿é—® https://huggingface.co/settings/tokens", file=sys.stderr)
            print("   2. åˆ›å»º token å¹¶è®¾ç½®ç¯å¢ƒå˜é‡: export HF_TOKEN=your_token", file=sys.stderr)
            print("   3. æˆ–è¿è¡Œ: huggingface-cli login", file=sys.stderr)

        return {
            "success": False,
            "error": error_msg,
            "audio_file": os.path.basename(audio_path),
            "speakers": [],
            "segments": []
        }

def save_diarization_results(result, output_dir, file_prefix):
    """ä¿å­˜è¯´è¯äººåˆ†ç¦»ç»“æœåˆ°æ–‡ä»¶"""
    saved_files = []

    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)

        # ä¿å­˜ JSON æ ¼å¼
        json_file = os.path.join(output_dir, f"{file_prefix}_diarization.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        saved_files.append(json_file)
        print(f"ğŸ’¾ ä¿å­˜JSON: {json_file}", file=sys.stderr)

        if result["success"]:
            # ä¿å­˜ CSV æ ¼å¼
            csv_file = os.path.join(output_dir, f"{file_prefix}_diarization.csv")
            with open(csv_file, 'w', encoding='utf-8') as f:
                f.write("start,end,duration,speaker,start_formatted,end_formatted\n")
                for seg in result["segments"]:
                    f.write(f"{seg['start']:.3f},{seg['end']:.3f},{seg['duration']:.3f},"
                           f"{seg['speaker']},{seg['start_formatted']},{seg['end_formatted']}\n")
            saved_files.append(csv_file)
            print(f"ğŸ’¾ ä¿å­˜CSV: {csv_file}", file=sys.stderr)

            # ä¿å­˜å¯è§†åŒ– Markdown
            md_file = os.path.join(output_dir, f"{file_prefix}_diarization.md")
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(f"# è¯´è¯äººåˆ†ç¦»ç»“æœ\n\n")
                f.write(f"**éŸ³é¢‘æ–‡ä»¶**: {result['audio_file']}  \n")
                f.write(f"**è¯´è¯äººæ•°é‡**: {result['num_speakers']}  \n")
                f.write(f"**åˆ†å‰²ç‰‡æ®µ**: {len(result['segments'])}  \n")
                f.write(f"**å¤„ç†æ—¶é—´**: {result['processing_time']:.2f} ç§’  \n\n")

                f.write("## è¯´è¯äººåˆ—è¡¨\n\n")
                for i, speaker in enumerate(result['speakers'], 1):
                    speaker_segments = [seg for seg in result['segments'] if seg['speaker'] == speaker]
                    total_time = sum(seg['duration'] for seg in speaker_segments)
                    f.write(f"- **{speaker}**: {len(speaker_segments)} ä¸ªç‰‡æ®µ, æ€»æ—¶é•¿ {total_time:.1f} ç§’\n")

                f.write("\n## æ—¶é—´çº¿\n\n")
                for seg in result['segments']:
                    f.write(f"**[{seg['start_formatted'][:8]} - {seg['end_formatted'][:8]}]** "
                           f"{seg['speaker']} ({seg['duration']:.1f}s)\n\n")

            saved_files.append(md_file)
            print(f"ğŸ’¾ ä¿å­˜Markdown: {md_file}", file=sys.stderr)

        return saved_files

    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}", file=sys.stderr)
        return saved_files

def main():
    parser = argparse.ArgumentParser(description='PyAnnote è¯´è¯äººåˆ†ç¦»å·¥å…·')
    parser.add_argument('audio_file', help='éŸ³é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--num-speakers', type=int, help='æŒ‡å®šè¯´è¯äººæ•°é‡ï¼ˆç•™ç©ºåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('--min-speakers', type=int, default=1, help='æœ€å°‘è¯´è¯äººæ•°é‡')
    parser.add_argument('--max-speakers', type=int, default=10, help='æœ€å¤šè¯´è¯äººæ•°é‡')
    parser.add_argument('--output-dir', help='ä¿å­˜ç»“æœçš„ç›®å½•')
    parser.add_argument('--file-prefix', default='pyannote',
                      help='ä¿å­˜æ–‡ä»¶çš„å‰ç¼€')

    args = parser.parse_args()

    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.audio_file):
        print(json.dumps({
            "success": False,
            "error": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.audio_file}",
            "speakers": [],
            "segments": []
        }, ensure_ascii=False))
        sys.exit(1)

    # æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
    result = diarize_audio(
        args.audio_file,
        num_speakers=args.num_speakers,
        min_speakers=args.min_speakers,
        max_speakers=args.max_speakers
    )

    # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.output_dir and result["success"]:
        saved_files = save_diarization_results(
            result,
            args.output_dir,
            args.file_prefix
        )
        result["savedFiles"] = saved_files

    # è¾“å‡ºç»“æœï¼ˆJSONæ ¼å¼åˆ°stdoutï¼Œç”¨äºç®¡é“é€šä¿¡ï¼‰
    print(json.dumps(result, ensure_ascii=False))

    # è¿”å›çŠ¶æ€ç 
    sys.exit(0 if result["success"] else 1)

if __name__ == "__main__":
    main()