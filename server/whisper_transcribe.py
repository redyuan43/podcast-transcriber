#!/usr/bin/env python3
"""
æœ¬åœ°Faster-Whisperè½¬å½•è„šæœ¬
æ”¯æŒå•æ–‡ä»¶å’Œæ‰¹é‡è½¬å½•
"""

import sys
import json
import argparse
import time
from pathlib import Path
from faster_whisper import WhisperModel

class LocalWhisperTranscriber:
    def __init__(self, model_size="base", device="cpu", compute_type="int8"):
        """
        åˆå§‹åŒ–Faster-Whisperæ¨¡å‹
        
        Args:
            model_size: æ¨¡å‹å¤§å° ("tiny", "base", "small", "medium", "large-v3")
            device: è®¾å¤‡ç±»å‹ ("cpu", "cuda")
            compute_type: è®¡ç®—ç±»å‹ ("int8", "int16", "float16", "float32")
        """
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½Whisperæ¨¡å‹: {model_size}", file=sys.stderr)
        self.model = WhisperModel(model_size, device=device, compute_type=compute_type)
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ", file=sys.stderr)

    def transcribe_file(self, audio_path, language=None):
        """
        è½¬å½•å•ä¸ªéŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: æŒ‡å®šè¯­è¨€ (Noneä¸ºè‡ªåŠ¨æ£€æµ‹)
        
        Returns:
            dict: è½¬å½•ç»“æœ
        """
        try:
            print(f"ğŸ¤ å¼€å§‹è½¬å½•: {audio_path}", file=sys.stderr)
            start_time = time.time()
            
            # æ‰§è¡Œè½¬å½•
            segments, info = self.model.transcribe(
                audio_path, 
                language=language,
                vad_filter=True,  # å¯ç”¨è¯­éŸ³æ´»åŠ¨æ£€æµ‹
                vad_parameters=dict(min_silence_duration_ms=500)
            )
            
            # æ”¶é›†æ‰€æœ‰ç‰‡æ®µ
            transcript_segments = []
            full_text = ""
            
            for segment in segments:
                segment_dict = {
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                }
                transcript_segments.append(segment_dict)
                full_text += segment.text.strip() + " "
            
            duration = time.time() - start_time
            
            result = {
                "success": True,
                "file": str(audio_path),
                "text": full_text.strip(),
                "segments": transcript_segments,
                "language": info.language,
                "language_probability": info.language_probability,
                "duration": info.duration,
                "processing_time": round(duration, 2)
            }
            
            print(f"âœ… è½¬å½•å®Œæˆ: {duration:.1f}ç§’", file=sys.stderr)
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "file": str(audio_path),
                "error": str(e),
                "text": ""
            }
            print(f"âŒ è½¬å½•å¤±è´¥: {e}", file=sys.stderr)
            return error_result

    def transcribe_multiple(self, audio_paths, language=None):
        """
        æ‰¹é‡è½¬å½•å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_paths: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            language: æŒ‡å®šè¯­è¨€
        
        Returns:
            list: è½¬å½•ç»“æœåˆ—è¡¨
        """
        results = []
        total_files = len(audio_paths)
        
        print(f"ğŸ“„ å¼€å§‹æ‰¹é‡è½¬å½• {total_files} ä¸ªæ–‡ä»¶", file=sys.stderr)
        
        for i, audio_path in enumerate(audio_paths, 1):
            print(f"ğŸµ å¤„ç†æ–‡ä»¶ {i}/{total_files}: {Path(audio_path).name}", file=sys.stderr)
            result = self.transcribe_file(audio_path, language)
            results.append(result)
        
        return results

def main():
    parser = argparse.ArgumentParser(description="æœ¬åœ°Faster-WhisperéŸ³é¢‘è½¬å½•")
    parser.add_argument("files", nargs="+", help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", default="base", 
                       choices=["tiny", "base", "small", "medium", "large-v3"],
                       help="Whisperæ¨¡å‹å¤§å° (é»˜è®¤: base)")
    parser.add_argument("--language", help="æŒ‡å®šè¯­è¨€ä»£ç  (å¦‚: zh, en)")
    parser.add_argument("--device", default="cpu", 
                       choices=["cpu", "cuda"], help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--compute-type", default="int8",
                       choices=["int8", "int16", "float16", "float32"],
                       help="è®¡ç®—ç²¾åº¦")
    parser.add_argument("--output", help="è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    audio_files = []
    for file_path in args.files:
        path = Path(file_path)
        if not path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", file=sys.stderr)
            sys.exit(1)
        audio_files.append(str(path.absolute()))
    
    try:
        # åˆå§‹åŒ–è½¬å½•å™¨
        transcriber = LocalWhisperTranscriber(
            model_size=args.model,
            device=args.device,
            compute_type=args.compute_type.replace("-", "_")
        )
        
        # æ‰§è¡Œè½¬å½•
        if len(audio_files) == 1:
            result = transcriber.transcribe_file(audio_files[0], args.language)
        else:
            result = transcriber.transcribe_multiple(audio_files, args.language)
        
        # è¾“å‡ºç»“æœ
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}", file=sys.stderr)
        else:
            # è¾“å‡ºåˆ°stdout
            print(json.dumps(result, ensure_ascii=False))
    
    except KeyboardInterrupt:
        print("\nâš ï¸ è½¬å½•è¢«ç”¨æˆ·ä¸­æ–­", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()
