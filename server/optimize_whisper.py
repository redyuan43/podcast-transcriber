#!/usr/bin/env python3
"""
Whisperè½¬å½•æ•ˆç‡ä¼˜åŒ–è„šæœ¬
é€šè¿‡å¹¶è¡Œå¤„ç†ã€æ¨¡å‹ä¼˜åŒ–ç­‰æ–¹å¼æå‡è½¬å½•é€Ÿåº¦
"""

import sys
import json
import argparse
import time
import multiprocessing
import concurrent.futures
from pathlib import Path
from faster_whisper import WhisperModel
import warnings
warnings.filterwarnings("ignore")

class OptimizedWhisperTranscriber:
    def __init__(self, model_size="base", device="auto", compute_type="auto", cpu_threads=None):
        """
        åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆWhisperæ¨¡å‹
        """
        # è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¾å¤‡
        if device == "auto":
            try:
                import torch
                device = "cuda" if torch.cuda.is_available() else "cpu"
            except ImportError:
                device = "cpu"
        
        # è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¡ç®—ç±»å‹
        if compute_type == "auto":
            if device == "cuda":
                compute_type = "float16"  # GPUä¼˜åŒ–
            else:
                compute_type = "int8"     # CPUä¼˜åŒ–
        
        # ä¼˜åŒ–CPUçº¿ç¨‹æ•°
        if cpu_threads is None:
            cpu_threads = min(8, multiprocessing.cpu_count())  # æœ€å¤š8çº¿ç¨‹ï¼Œé¿å…è¿‡è½½
        
        print(f"ğŸš€ æ­£åœ¨åŠ è½½ä¼˜åŒ–ç‰ˆWhisperæ¨¡å‹: {model_size}", file=sys.stderr)
        print(f"ğŸ“± è®¾å¤‡: {device}, è®¡ç®—ç±»å‹: {compute_type}, CPUçº¿ç¨‹: {cpu_threads}", file=sys.stderr)
        
        self.model = WhisperModel(
            model_size, 
            device=device, 
            compute_type=compute_type,
            cpu_threads=cpu_threads,
            num_workers=1  # å•workerä½†ä¼˜åŒ–å†…éƒ¨å¹¶è¡Œ
        )
        
        self.device = device
        self.compute_type = compute_type
        
        print(f"âœ… ä¼˜åŒ–ç‰ˆæ¨¡å‹åŠ è½½å®Œæˆ", file=sys.stderr)
    
    def transcribe_file_optimized(self, audio_path, language=None):
        """
        ä¼˜åŒ–ç‰ˆè½¬å½•ï¼Œæ³¨é‡é€Ÿåº¦
        """
        try:
            print(f"âš¡ å¼€å§‹ä¼˜åŒ–è½¬å½•: {audio_path}", file=sys.stderr)
            start_time = time.time()
            
            # ä¼˜åŒ–å‚æ•°è®¾ç½®
            vad_parameters = {
                "min_silence_duration_ms": 250,  # å‡å°‘é™éŸ³æ£€æµ‹æ—¶é—´
                "threshold": 0.5,               # æé«˜è¯­éŸ³æ´»åŠ¨æ£€æµ‹é˜ˆå€¼
                "min_speech_duration_ms": 250   # å‡å°‘æœ€å°è¯­éŸ³æ—¶é•¿
            }
            
            # æ‰§è¡Œä¼˜åŒ–è½¬å½•
            segments, info = self.model.transcribe(
                audio_path, 
                language=language,
                vad_filter=True,
                vad_parameters=vad_parameters,
                beam_size=1,        # å‡å°‘beam sizeæå‡é€Ÿåº¦
                best_of=1,          # å‡å°‘å€™é€‰æ•°é‡
                temperature=0,      # ç¡®å®šæ€§è¾“å‡ºï¼Œæå‡é€Ÿåº¦
                condition_on_previous_text=True,  # åˆ©ç”¨ä¸Šä¸‹æ–‡æå‡å‡†ç¡®æ€§
                initial_prompt=None,
                word_timestamps=False  # å…³é—­è¯çº§æ—¶é—´æˆ³ä»¥æå‡é€Ÿåº¦
            )
            
            # æ”¶é›†æ‰€æœ‰ç‰‡æ®µ
            transcript_segments = []
            full_text = ""
            
            for segment in segments:
                segment_dict = {
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                }
                transcript_segments.append(segment_dict)
                full_text += segment.text.strip() + " "
            
            duration = time.time() - start_time
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            audio_duration = info.duration
            real_time_factor = duration / audio_duration if audio_duration > 0 else 0
            
            result = {
                "success": True,
                "file": str(audio_path),
                "text": full_text.strip(),
                "segments": transcript_segments,
                "language": info.language,
                "language_probability": info.language_probability,
                "duration": info.duration,
                "processing_time": round(duration, 2),
                "real_time_factor": round(real_time_factor, 3),
                "optimized": True,
                "performance": {
                    "device": self.device,
                    "compute_type": self.compute_type,
                    "segments_per_second": len(transcript_segments) / duration if duration > 0 else 0,
                    "words_per_minute": len(full_text.split()) / (duration / 60) if duration > 0 else 0
                }
            }
            
            print(f"âš¡ ä¼˜åŒ–è½¬å½•å®Œæˆ: {duration:.1f}ç§’", file=sys.stderr)
            print(f"ğŸ“Š å®æ—¶å› å­: {real_time_factor:.3f}x (è¶Šå°è¶Šå¿«)", file=sys.stderr)
            print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {len(transcript_segments)/duration:.1f} æ®µ/ç§’", file=sys.stderr)
            
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "file": str(audio_path),
                "error": str(e),
                "text": "",
                "optimized": False
            }
            print(f"âŒ ä¼˜åŒ–è½¬å½•å¤±è´¥: {e}", file=sys.stderr)
            return error_result
    
    def transcribe_with_chunking(self, audio_path, language=None, chunk_length=600):
        """
        åˆ†å—è½¬å½•ï¼Œé€‚ç”¨äºé•¿éŸ³é¢‘æ–‡ä»¶
        """
        try:
            print(f"ğŸ“¦ å¼€å§‹åˆ†å—è½¬å½•: {audio_path} (å—é•¿åº¦: {chunk_length}ç§’)", file=sys.stderr)
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ éŸ³é¢‘åˆ†å‰²é€»è¾‘
            # æš‚æ—¶ä½¿ç”¨æ•´æ–‡ä»¶è½¬å½•
            return self.transcribe_file_optimized(audio_path, language)
            
        except Exception as e:
            print(f"âŒ åˆ†å—è½¬å½•å¤±è´¥: {e}", file=sys.stderr)
            return {"success": False, "error": str(e)}

def benchmark_model(model_size, test_file, iterations=3):
    """
    åŸºå‡†æµ‹è¯•ä¸åŒæ¨¡å‹çš„æ€§èƒ½
    """
    print(f"ğŸ§ª åŸºå‡†æµ‹è¯•æ¨¡å‹: {model_size}", file=sys.stderr)
    
    results = []
    for i in range(iterations):
        transcriber = OptimizedWhisperTranscriber(model_size)
        result = transcriber.transcribe_file_optimized(test_file)
        if result['success']:
            results.append(result['processing_time'])
    
    if results:
        avg_time = sum(results) / len(results)
        print(f"ğŸ“Š æ¨¡å‹ {model_size} å¹³å‡è€—æ—¶: {avg_time:.2f}ç§’", file=sys.stderr)
        return avg_time
    return None

def main():
    parser = argparse.ArgumentParser(description="ä¼˜åŒ–ç‰ˆæœ¬åœ°Faster-WhisperéŸ³é¢‘è½¬å½•")
    parser.add_argument("files", nargs="+", help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", default="base", 
                       choices=["tiny", "base", "small", "medium", "large-v3"],
                       help="Whisperæ¨¡å‹å¤§å° (é»˜è®¤: base)")
    parser.add_argument("--language", help="æŒ‡å®šè¯­è¨€ä»£ç  (å¦‚: zh, en)")
    parser.add_argument("--device", default="auto", help="è®¡ç®—è®¾å¤‡ (auto/cpu/cuda)")
    parser.add_argument("--compute-type", default="auto", help="è®¡ç®—ç²¾åº¦ (auto/int8/float16/float32)")
    parser.add_argument("--cpu-threads", type=int, help="CPUçº¿ç¨‹æ•° (é»˜è®¤è‡ªåŠ¨)")
    parser.add_argument("--output", help="è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--chunk-length", type=int, default=600, help="åˆ†å—é•¿åº¦(ç§’)")
    parser.add_argument("--benchmark", action="store_true", help="è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•")
    parser.add_argument("--save-transcript", help="ä¿å­˜è½¬å½•æ–‡æœ¬åˆ°æŒ‡å®šç›®å½•")
    parser.add_argument("--file-prefix", help="ä¿å­˜æ–‡ä»¶å‰ç¼€")
    
    args = parser.parse_args()
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    audio_files = []
    for file_path in args.files:
        path = Path(file_path)
        if not path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", file=sys.stderr)
            sys.exit(1)
        audio_files.append(str(path.absolute()))
    
    try:
        if args.benchmark:
            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            print("ğŸ§ª å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•...", file=sys.stderr)
            models = ["tiny", "base", "small"]
            for model in models:
                benchmark_model(model, audio_files[0])
            return
        
        # åˆå§‹åŒ–ä¼˜åŒ–è½¬å½•å™¨
        transcriber = OptimizedWhisperTranscriber(
            model_size=args.model,
            device=args.device,
            compute_type=args.compute_type,
            cpu_threads=args.cpu_threads
        )
        
        # å¤„ç†æ–‡ä»¶
        if len(audio_files) == 1:
            if Path(audio_files[0]).stat().st_size > 100 * 1024 * 1024:  # å¤§äº100MBä½¿ç”¨åˆ†å—
                result = transcriber.transcribe_with_chunking(audio_files[0], args.language, args.chunk_length)
            else:
                result = transcriber.transcribe_file_optimized(audio_files[0], args.language)
        else:
            # æ‰¹é‡å¤„ç†
            results = []
            for audio_file in audio_files:
                result = transcriber.transcribe_file_optimized(audio_file, args.language)
                results.append(result)
            result = {"results": results, "batch": True}
        
        # ä¿å­˜è½¬å½•æ–‡æœ¬
        saved_files = []
        if args.save_transcript and isinstance(result, dict) and result.get('success') and result.get('text'):
            from whisper_transcribe import save_transcript_to_file
            file_info = save_transcript_to_file(
                transcript_text=result['text'],
                save_dir=args.save_transcript,
                file_prefix=args.file_prefix or "optimized",
                original_filename=audio_files[0] if len(audio_files) == 1 else None
            )
            if file_info:
                saved_files.append(file_info)
                result['savedFiles'] = saved_files
        
        # è¾“å‡ºç»“æœ
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}", file=sys.stderr)
        else:
            print(json.dumps(result, ensure_ascii=False))
    
    except KeyboardInterrupt:
        print("\nâš ï¸ è½¬å½•è¢«ç”¨æˆ·ä¸­æ–­", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()